{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pydantic import BaseModel, field_validator, ValidationError\n",
    "import os\n",
    "from datetime import  datetime\n",
    "import phonenumbers\n",
    "import os,tabulate\n",
    "import numpy as np\n",
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loading_dataset(filename,filename1,filename2,filename3,filename4):\n",
    "    path = os.path.abspath('C:/Users/Balli/Pictures/')\n",
    "    if path:\n",
    "        fullpath = os.path.join(path,filename)\n",
    "        fullpath1 = os.path.join(path,filename1)\n",
    "        fullpath2 = os.path.join(path,filename2)\n",
    "        fullpath3 = os.path.join(path,filename3)\n",
    "        fullpath4 = os.path.join(path,filename4)\n",
    "\n",
    "        dataset_weblog = pd.read_csv(fullpath)\n",
    "        dataset_ipinfo = pd.read_csv(fullpath1)\n",
    "        dataset_product= pd.read_csv(fullpath2)\n",
    "        dataset_transaction= pd.read_csv(fullpath3)\n",
    "        dataset_customer = pd.read_csv(fullpath4)\n",
    "\n",
    "        df = dataset_weblog.copy()\n",
    "        df1 = dataset_ipinfo.copy()\n",
    "        df2 = dataset_product.copy()\n",
    "        df3 = dataset_transaction.copy()\n",
    "        customer_dataset = dataset_customer.copy()\n",
    "\n",
    "#perform a join querry of our two dataset that are related \n",
    "        weblog_ipinfo_dataset = pd.merge(df,df1, on='IP',how='left')\n",
    "        transactn_product_dataset = pd.merge(df3,df2, on='ProductID',how='left')\n",
    "        return weblog_ipinfo_dataset,transactn_product_dataset,df,customer_dataset\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def model_creation():\n",
    "    class customerweb_infomodel(BaseModel):\n",
    "        timespent_perday: int\n",
    "        no_pages_visited: int\n",
    "        location: str\n",
    "        hour_session_starts: int\n",
    "        was_there_purchase: int\n",
    "        \n",
    "# creating validation for column number of pages visited\n",
    "        @field_validator('no_pages_visited')\n",
    "        def check_pages_visited(cls, value):\n",
    "            if value <= 0:\n",
    "                raise ValidationError('Pages visited field can not be less than 0')\n",
    "            else:\n",
    "                return value\n",
    "            \n",
    "# creating validation for column was there a purchase to convert integer to a string answer of Yes or No \n",
    "        @field_validator('was_there_purchase')\n",
    "        def purchase(cls, value):\n",
    "            if value == 1:\n",
    "                return 'Yes'\n",
    "            else:\n",
    "                return 'No'\n",
    "\n",
    "    class transaction_model(BaseModel):\n",
    "        productname:str\n",
    "        price: float\n",
    "        date: datetime\n",
    "        hour_of_transaction: int\n",
    "\n",
    "        @field_validator('price')\n",
    "        def check_price(cls, value):\n",
    "            if value:\n",
    "                return f'${value}'\n",
    "            elif value <= 0:\n",
    "                raise ValidationError('Price must be greater than 0')\n",
    "            else:\n",
    "                return None\n",
    "            \n",
    "\n",
    "    class webpages_visitedmodel(BaseModel):\n",
    "        last_web_pagevisited: str\n",
    "        no_of_time_pagevisited: int\n",
    "\n",
    "    return {\n",
    "        'customerweb_infomodel': customerweb_infomodel,\n",
    "        'transaction_model': transaction_model,\n",
    "        'webpages_visitedmodel': webpages_visitedmodel}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customerweb_record(df):           \n",
    "        model = model_creation()\n",
    "        customerweb_infomodel = model['customerweb_infomodel']        \n",
    "        if not df.empty:        \n",
    "                df['timestamp'] = pd.to_datetime(df['timestamp'],unit='s')\n",
    "\n",
    "        # filtering the date out of the datetime\n",
    "                df['date'] = df['timestamp'].dt.date\n",
    "\n",
    "        # filtering the hour of user session out of datetime\n",
    "                df['hour'] = df['timestamp'].dt.hour\n",
    "\n",
    "                \n",
    "                customerweb_recordtable=df.groupby(['UserId','date','hour','Location','product_to_cart']).agg(\n",
    "                                                timespentdaily=('Duration','sum'),\n",
    "                                                pages_visited=('Address','count')).reset_index()\n",
    "                \n",
    "                customerweb_recordtable.drop_duplicates(subset=['UserId'])\n",
    "                \n",
    "\n",
    "        # defining a variable list to store data for the model customer_web_info       \n",
    "                data_list = []\n",
    "        # Iterating over the customer web record table to load our model with data\n",
    "                \n",
    "                for _, row in customerweb_recordtable.iterrows():\n",
    "                        try:    \n",
    "                                customerweb_table = customerweb_infomodel(timespent_perday=row['timespentdaily'] ,\n",
    "                                                        no_pages_visited=row['pages_visited'],\n",
    "                                                        location=row['Location'],\n",
    "                                                        hour_session_starts=row['hour'],\n",
    "                                                        was_there_purchase=row['product_to_cart'])\n",
    "                                \n",
    "                                data_list.append(customerweb_table.model_dump())\n",
    "                        except Exception as error:\n",
    "                                print(f'error:{error}')\n",
    "\n",
    "        # converting data list to pandas dataframe\n",
    "                if data_list:\n",
    "                        customerweb_record_df=pd.DataFrame(data_list)\n",
    "                        print(tabulate.tabulate(customerweb_record_df.set_index('timespent_perday'),headers=customerweb_record_df.columns.tolist(),tablefmt = 'heavy_grid'))\n",
    "                \n",
    "        #saving our file/dataset as csv\n",
    "                customerweb_record_df.to_csv('Customer web record.csv', index=False)\n",
    "                print('Customer web record saved successfully')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transactn_record(df):\n",
    "    model = model_creation()\n",
    "    transaction_model = model['transaction_model']\n",
    "    if not df.empty:\n",
    "    \n",
    "# converting to datetime to be able to get the date and hour of  daily transaction\n",
    "        df['transactn_time'] = pd.to_datetime(df['time_transactn'],unit='s')\n",
    "\n",
    "# filtering the date out of the datetime\n",
    "        df['date'] = df['transactn_time'].dt.date\n",
    "\n",
    "#filtering the hour of transaction out of datetime\n",
    "        df['hour'] = df['transactn_time'].dt.hour\n",
    "\n",
    "#creating a dictionary of our new formated dataset\n",
    "        DictData={'date':df['date'],\n",
    "                'houroftransactn':df['hour'],\n",
    "                'productname':df['Productdescriptn'],\n",
    "                'price':df['price']}\n",
    "\n",
    "#converting to pandas dataframe\n",
    "        final_dataset=pd.DataFrame(DictData)\n",
    "    \n",
    " #stacking final engineered dataset into the transaction table or model earlier defined above\n",
    "\n",
    "        transaction_datalist = []\n",
    "        # iterating over finaldata1 to load our model\n",
    "        for _, row in final_dataset.iterrows():\n",
    "            transaction_table = transaction_model(productname=row['productname'],\n",
    "                                                date= row['date'], \n",
    "                                                hour_of_transaction=row['houroftransactn'], \n",
    "                                                price=row['price'])\n",
    "            \n",
    "            transaction_datalist.append(transaction_table.model_dump())\n",
    "# converting transaction datalist to pandas dataframe\n",
    "        if transaction_datalist:\n",
    "                transactn_df=pd.DataFrame(transaction_datalist)\n",
    "                print(tabulate.tabulate(transactn_df.set_index('productname'),headers=transactn_df.columns.tolist(),tablefmt = 'heavy_grid'))\n",
    "                # saving our data table as csv\n",
    "                transactn_df.to_csv('transaction record.csv', index=False)\n",
    "                print('transaction record saved successfully')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lastwebpage_visited_no(df):\n",
    "    model = model_creation()\n",
    "    webpages_visitedmodel = model['webpages_visitedmodel']\n",
    "    if not df.empty:\n",
    "        df.fillna({'Link': 'Link unavailable'},inplace = True)\n",
    "\n",
    "# Group by the Address column and count occurrences\n",
    "        webpages_visitedtimes_df = df.groupby('Address').size().reset_index(name='count')\n",
    "\n",
    "#set a list variable to store our table data\n",
    "        datatable = []\n",
    "\n",
    "#iterate over the last_page_count table and load into our model\n",
    "        for _, row in webpages_visitedtimes_df.iterrows():\n",
    "            model_data=webpages_visitedmodel(last_web_pagevisited=row['Address'],\n",
    "                                                no_of_time_pagevisited=row['count'])\n",
    "            datatable.append(model_data.model_dump())\n",
    "#convert our data table 3 into pandas dataframe\n",
    "        if datatable:\n",
    "            lastweb_visited_no=pd.DataFrame(datatable)\n",
    "            print(tabulate.tabulate(lastweb_visited_no.set_index('last_web_pagevisited'),headers=lastweb_visited_no.columns.tolist(),tablefmt = 'heavy_grid'))\n",
    "# saving our file/data  as csv\n",
    "            lastweb_visited_no.to_csv('Customer last webpage vistedcount.csv', index=False)\n",
    "            print(' Document saved successfully')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def promotion_record(df):\n",
    "\n",
    "    if not df.empty:\n",
    "\n",
    "        # The Gender column is empty, and since there is no module in python currently to decipher\n",
    "        # male or female from the names. it became sacrosanct to use Excel and manually fill this column since\n",
    "        # we can decipher male names from female names by bare looking at it.\n",
    "\n",
    "        # now let us deal wit outliers\n",
    "        # from the dataset it can be noticed that the age column have an outlier which is 500, because no human in the generation\n",
    "        # can live to 500 years\n",
    "\n",
    "        # because this dataset is no many and we can easily spot outliers so we may not need to use IQR method but directly\n",
    "        # replace the outlier with the mean or median or mode as the case may be, but for this dataset, i may have to use mean\n",
    "        \n",
    "        # Now i am going t replace the outlier with the mean_age\n",
    "        df['age'] = df['age'].apply( lambda x: df['age'].mean() if x >= 500 else x)\n",
    "        \n",
    "# replacing the null value in the age column with the median age\n",
    "        df.fillna({'age':df['age'].median()},inplace=True)\n",
    "        df['age'] = df['age'].astype(int)\n",
    "\n",
    "# Now cleaning the Education column and replacing the null with the most frequent education category\n",
    "\n",
    "        df['education'].value_counts(dropna=False)\n",
    "        df.fillna({'education':df['education'].mode()[0]},inplace=True)\n",
    "# stripping off excess whitespaces in the Education column\n",
    "        df['education']= df['education'].str.strip()\n",
    "\n",
    "# Now cleaning the income column to replace the null with the mean income and adding the $ sign\n",
    "        \n",
    "        df.fillna({'income':round(df['income'].mean(),2)},inplace=True)\n",
    "        def add_currencySign(income):\n",
    "            if income:\n",
    "                return '${:,}'.format(income)\n",
    "            else:\n",
    "                return None\n",
    "        df['income']= df['income'].apply(add_currencySign)\n",
    "\n",
    "# Now cleaning the Consent column to replace any string to integer and convert datatype to int\n",
    "        df['consent']= df['consent'].apply(lambda x: 1 if x == 'i' else x).astype(int)\n",
    "\n",
    "# Cleaning the phone number column and also creating a link for one-time click dial Filling any phone number that is less 10 digit\n",
    "\n",
    "        df['phone']= df['phone'].apply(lambda x: int(random.randint(10**9,10**10)) if pd.isnull(x) else int(x)).astype(str).str.zfill(10)\n",
    "\n",
    "# Trimming any phone number that is greater than 10 digits\n",
    "        df['phone'] = df['phone'].str.slice(0,9)\n",
    "\n",
    "# Now converting the phone number column to proper phone number standard using the python phonenumber module\n",
    "        def format_phone_number(phone):\n",
    "            try:\n",
    "                # Parse the phone number\n",
    "                parsed_number = phonenumbers.parse(phone, \"CA\")\n",
    "                # Format the phone number in E.164 format\n",
    "                formatted_number = phonenumbers.format_number(parsed_number, phonenumbers.PhoneNumberFormat.E164)\n",
    "                return formatted_number\n",
    "            except phonenumbers.NumberParseException:\n",
    "                return phone \n",
    "            \n",
    "# Now applying the function format_phone_number to the phone column of our dataset\n",
    "        df['phone']= df['phone'].apply(format_phone_number)\n",
    "\n",
    "# Final step is to create a link on the phone column so that this can aid auto-dail by creating a function\n",
    "\n",
    "        def clickable_phone(phone):\n",
    "            if phone:\n",
    "                return f'<a href=\"{phone}\">{phone}</a>'\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "        df['phone']= df['phone'].apply(clickable_phone)\n",
    "\n",
    "        print(tabulate.tabulate(df.set_index('name'),headers=df.columns.tolist(),tablefmt = 'heavy_grid'))\n",
    "\n",
    "# To enable the customer rep to dial customer phone numbers automatically, we need to save te dataset in an html format\n",
    "# this will enable the dataset to e opened through a browser and then giving the link to auto dial a number\n",
    "\n",
    "        df.to_html('customerdataset.html',escape=False,index=False)\n",
    "        print('dataset saved in html file successfully')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Balli\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pydantic\\main.py:364: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `int` but got `str` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "c:\\Users\\Balli\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pydantic\\main.py:364: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `float` but got `str` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┏━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃   timespent_perday ┃   no_pages_visited ┃ location                  ┃   hour_session_starts ┃ was_there_purchase   ┃\n",
      "┣━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃                195 ┃                  3 ┃ Ontario, Canada           ┃                    19 ┃ No                   ┃\n",
      "┣━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃                 41 ┃                  1 ┃ Ontario, Canada           ┃                    19 ┃ Yes                  ┃\n",
      "┣━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃                272 ┃                  3 ┃ Texas, United States      ┃                    19 ┃ No                   ┃\n",
      "┣━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃                 60 ┃                  1 ┃ Texas, United States      ┃                    19 ┃ Yes                  ┃\n",
      "┣━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃                204 ┃                  4 ┃ Texas, United States      ┃                    19 ┃ No                   ┃\n",
      "┣━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃                 54 ┃                  4 ┃ California, United States ┃                    18 ┃ No                   ┃\n",
      "┣━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃                 66 ┃                  1 ┃ California, United States ┃                    18 ┃ Yes                  ┃\n",
      "┣━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃                482 ┃                  4 ┃ California, United States ┃                    18 ┃ No                   ┃\n",
      "┣━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃                148 ┃                  3 ┃ California, United States ┃                    18 ┃ Yes                  ┃\n",
      "┣━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃                349 ┃                  4 ┃ Texas, United States      ┃                    19 ┃ No                   ┃\n",
      "┣━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃                121 ┃                  2 ┃ Texas, United States      ┃                    19 ┃ Yes                  ┃\n",
      "┣━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃                106 ┃                  3 ┃ Ohio, United States       ┃                    19 ┃ No                   ┃\n",
      "┣━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃                102 ┃                  3 ┃ Ohio, United States       ┃                    19 ┃ Yes                  ┃\n",
      "┣━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃                198 ┃                  3 ┃ California, United States ┃                    18 ┃ No                   ┃\n",
      "┗━━━━━━━━━━━━━━━━━━━━┻━━━━━━━━━━━━━━━━━━━━┻━━━━━━━━━━━━━━━━━━━━━━━━━━━┻━━━━━━━━━━━━━━━━━━━━━━━┻━━━━━━━━━━━━━━━━━━━━━━┛\n",
      "Customer web record saved successfully\n",
      "┏━━━━━━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃ productname   ┃ price   ┃ date                ┃   hour_of_transaction ┃\n",
      "┣━━━━━━━━━━━━━━━╋━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ Red Pants     ┃ $10.99  ┃ 2020-07-28 00:00:00 ┃                    18 ┃\n",
      "┣━━━━━━━━━━━━━━━╋━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ Red Pants     ┃ $10.99  ┃ 2020-07-28 00:00:00 ┃                    19 ┃\n",
      "┣━━━━━━━━━━━━━━━╋━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ Flower Dress  ┃ $25.99  ┃ 2020-07-28 00:00:00 ┃                    20 ┃\n",
      "┣━━━━━━━━━━━━━━━╋━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ Orange Belt   ┃ $13.99  ┃ 2020-07-28 00:00:00 ┃                    20 ┃\n",
      "┣━━━━━━━━━━━━━━━╋━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ Pink Shorts   ┃ $9.99   ┃ 2020-07-28 00:00:00 ┃                    20 ┃\n",
      "┣━━━━━━━━━━━━━━━╋━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ Red Pants     ┃ $10.99  ┃ 2020-07-28 00:00:00 ┃                    21 ┃\n",
      "┣━━━━━━━━━━━━━━━╋━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ Flower Dress  ┃ $25.99  ┃ 2020-07-28 00:00:00 ┃                    21 ┃\n",
      "┣━━━━━━━━━━━━━━━╋━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ Orange Belt   ┃ $13.99  ┃ 2020-07-28 00:00:00 ┃                    21 ┃\n",
      "┣━━━━━━━━━━━━━━━╋━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ Yellow Skirt  ┃ $17.99  ┃ 2020-07-28 00:00:00 ┃                    21 ┃\n",
      "┣━━━━━━━━━━━━━━━╋━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ Red Pants     ┃ $10.99  ┃ 2020-08-02 00:00:00 ┃                     8 ┃\n",
      "┣━━━━━━━━━━━━━━━╋━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ Pink Shorts   ┃ $9.99   ┃ 2020-08-02 00:00:00 ┃                    11 ┃\n",
      "┣━━━━━━━━━━━━━━━╋━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ Blue Pants    ┃ $11.99  ┃ 2020-08-02 00:00:00 ┃                    11 ┃\n",
      "┣━━━━━━━━━━━━━━━╋━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ Green Pants   ┃ $12.99  ┃ 2020-08-02 00:00:00 ┃                    11 ┃\n",
      "┣━━━━━━━━━━━━━━━╋━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ Yellow Skirt  ┃ $17.99  ┃ 2020-08-02 00:00:00 ┃                    11 ┃\n",
      "┣━━━━━━━━━━━━━━━╋━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ Red Pants     ┃ $10.99  ┃ 2020-08-02 00:00:00 ┃                    11 ┃\n",
      "┣━━━━━━━━━━━━━━━╋━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ Blue Pants    ┃ $11.99  ┃ 2020-08-02 00:00:00 ┃                    11 ┃\n",
      "┣━━━━━━━━━━━━━━━╋━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ Green Pants   ┃ $12.99  ┃ 2020-08-02 00:00:00 ┃                    11 ┃\n",
      "┣━━━━━━━━━━━━━━━╋━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ Blue Pants    ┃ $11.99  ┃ 2020-08-02 00:00:00 ┃                    11 ┃\n",
      "┣━━━━━━━━━━━━━━━╋━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ Green Pants   ┃ $12.99  ┃ 2020-08-02 00:00:00 ┃                    11 ┃\n",
      "┣━━━━━━━━━━━━━━━╋━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ Red Pants     ┃ $10.99  ┃ 2020-08-02 00:00:00 ┃                    12 ┃\n",
      "┣━━━━━━━━━━━━━━━╋━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ Yellow Skirt  ┃ $17.99  ┃ 2020-08-02 00:00:00 ┃                    12 ┃\n",
      "┣━━━━━━━━━━━━━━━╋━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ Red Pants     ┃ $10.99  ┃ 2020-08-02 00:00:00 ┃                    12 ┃\n",
      "┣━━━━━━━━━━━━━━━╋━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ Pink Shorts   ┃ $9.99   ┃ 2020-08-02 00:00:00 ┃                    12 ┃\n",
      "┣━━━━━━━━━━━━━━━╋━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ Yellow Skirt  ┃ $17.99  ┃ 2020-08-02 00:00:00 ┃                    12 ┃\n",
      "┣━━━━━━━━━━━━━━━╋━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ Blue Pants    ┃ $11.99  ┃ 2020-08-02 00:00:00 ┃                    12 ┃\n",
      "┣━━━━━━━━━━━━━━━╋━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ Green Pants   ┃ $12.99  ┃ 2020-08-02 00:00:00 ┃                    12 ┃\n",
      "┣━━━━━━━━━━━━━━━╋━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ Pink Shorts   ┃ $9.99   ┃ 2020-08-02 00:00:00 ┃                    12 ┃\n",
      "┣━━━━━━━━━━━━━━━╋━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ Red Pants     ┃ $10.99  ┃ 2020-08-02 00:00:00 ┃                    14 ┃\n",
      "┣━━━━━━━━━━━━━━━╋━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ Pink Shorts   ┃ $9.99   ┃ 2020-08-02 00:00:00 ┃                    16 ┃\n",
      "┣━━━━━━━━━━━━━━━╋━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ Yellow Skirt  ┃ $17.99  ┃ 2020-08-02 00:00:00 ┃                    17 ┃\n",
      "┣━━━━━━━━━━━━━━━╋━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ Red Pants     ┃ $10.99  ┃ 2020-08-07 00:00:00 ┃                     8 ┃\n",
      "┣━━━━━━━━━━━━━━━╋━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ Flower Dress  ┃ $25.99  ┃ 2020-08-07 00:00:00 ┃                     8 ┃\n",
      "┣━━━━━━━━━━━━━━━╋━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ Orange Belt   ┃ $13.99  ┃ 2020-08-07 00:00:00 ┃                     8 ┃\n",
      "┣━━━━━━━━━━━━━━━╋━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ Blue Pants    ┃ $11.99  ┃ 2020-08-07 00:00:00 ┃                    13 ┃\n",
      "┣━━━━━━━━━━━━━━━╋━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ Green Pants   ┃ $12.99  ┃ 2020-08-07 00:00:00 ┃                    13 ┃\n",
      "┣━━━━━━━━━━━━━━━╋━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ Red Pants     ┃ $10.99  ┃ 2020-08-07 00:00:00 ┃                    14 ┃\n",
      "┣━━━━━━━━━━━━━━━╋━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ Blue Pants    ┃ $11.99  ┃ 2020-08-07 00:00:00 ┃                    16 ┃\n",
      "┣━━━━━━━━━━━━━━━╋━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ Green Pants   ┃ $12.99  ┃ 2020-08-07 00:00:00 ┃                    16 ┃\n",
      "┣━━━━━━━━━━━━━━━╋━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ Red Pants     ┃ $10.99  ┃ 2020-08-07 00:00:00 ┃                    18 ┃\n",
      "┣━━━━━━━━━━━━━━━╋━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ Flower Dress  ┃ $25.99  ┃ 2020-08-07 00:00:00 ┃                    20 ┃\n",
      "┣━━━━━━━━━━━━━━━╋━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ Orange Belt   ┃ $13.99  ┃ 2020-08-07 00:00:00 ┃                    20 ┃\n",
      "┗━━━━━━━━━━━━━━━┻━━━━━━━━━┻━━━━━━━━━━━━━━━━━━━━━┻━━━━━━━━━━━━━━━━━━━━━━━┛\n",
      "transaction record saved successfully\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃ last_web_pagevisited              ┃   no_of_time_pagevisited ┃\n",
      "┣━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ www.store.com/checkout_trans#1543 ┃                        2 ┃\n",
      "┣━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ www.store.com/checkout_trans#1545 ┃                        1 ┃\n",
      "┣━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ www.store.com/checkout_trans#1546 ┃                        1 ┃\n",
      "┣━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ www.store.com/checkout_trans#1547 ┃                        2 ┃\n",
      "┣━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ www.store.com/checkout_trans#1548 ┃                        3 ┃\n",
      "┣━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ www.store.com/item#1304139212     ┃                        1 ┃\n",
      "┣━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ www.store.com/item#1304139220     ┃                        1 ┃\n",
      "┣━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ www.store.com/item#205616461      ┃                        3 ┃\n",
      "┣━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ www.store.com/item#558925278      ┃                        4 ┃\n",
      "┣━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ www.store.com/item#733001998      ┃                        4 ┃\n",
      "┣━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ www.store.com/item#762451459      ┃                        1 ┃\n",
      "┣━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ www.store.com/main#               ┃                       11 ┃\n",
      "┣━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ www.store.com/ty#A39HTATAQ9V7YF   ┃                        1 ┃\n",
      "┣━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ www.store.com/ty#AKJHHD5VEH7VG    ┃                        1 ┃\n",
      "┣━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ www.store.com/verifypaymnt#1543   ┃                        1 ┃\n",
      "┣━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ www.store.com/verifypaymnt#1545   ┃                        1 ┃\n",
      "┣━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━━━━┫\n",
      "┃ www.store.com/verifypaymnt#1546   ┃                        1 ┃\n",
      "┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┻━━━━━━━━━━━━━━━━━━━━━━━━━━┛\n",
      " Document saved successfully\n",
      "        name                                  phone  age       income  \\\n",
      "0       Thom  <a href=\"+1604907178\">+1604907178</a>   67   $754,298.0   \n",
      "1       Thom  <a href=\"+1908876453\">+1908876453</a>   23     $9,000.0   \n",
      "2      Colin  <a href=\"+1604675894\">+1604675894</a>   54    $62,840.0   \n",
      "3      Colin  <a href=\"+1604675894\">+1604675894</a>   54    $62,840.0   \n",
      "4       Phil  <a href=\"+1509524718\">+1509524718</a>   12    $78,000.0   \n",
      "5         Ed  <a href=\"+1509826727\">+1509826727</a>   35   $445,566.0   \n",
      "6     Johnny  <a href=\"+1604918675\">+1604918675</a>   87   $212,121.0   \n",
      "7      Sarah  <a href=\"+1402289101\">+1402289101</a>   65    $36,000.0   \n",
      "8       Yoda  <a href=\"+1642098256\">+1642098256</a>   62    $49,382.0   \n",
      "9     Alexis  <a href=\"+1604897178\">+1604897178</a>   44    $12,344.0   \n",
      "10     Hanna  <a href=\"+1509786098\">+1509786098</a>   32     $1,010.0   \n",
      "11    Rachel  <a href=\"+1709878923\">+1709878923</a>   28   $100,000.0   \n",
      "12      Tina  <a href=\"+1509200775\">+1509200775</a>   19    $77,000.0   \n",
      "13      Paul  <a href=\"+1509817293\">+1509817293</a>   50  $136,938.92   \n",
      "14   Georgia  <a href=\"+1000090082\">+1000090082</a>   44  $136,938.92   \n",
      "15     Riana  <a href=\"+1108543575\">+1108543575</a>   44  $136,938.92   \n",
      "16       Pop  <a href=\"+1797349258\">+1797349258</a>   44  $136,938.92   \n",
      "17     Hanna  <a href=\"+1509786098\">+1509786098</a>   32     $1,010.0   \n",
      "18   Preston  <a href=\"+1709878923\">+1709878923</a>   54  $136,938.92   \n",
      "19    MayMay  <a href=\"+1070989875\">+1070989875</a>   44    $62,840.0   \n",
      "20    Brenda  <a href=\"+1709878954\">+1709878954</a>   38    $43,124.0   \n",
      "21    George  <a href=\"+1709878929\">+1709878929</a>   43    $62,840.0   \n",
      "22     Poppy  <a href=\"+1710000000\">+1710000000</a>   41   $100,100.0   \n",
      "23   Herbert  <a href=\"+1444878923\">+1444878923</a>   76    $23,876.0   \n",
      "24    Walker  <a href=\"+1234567890\">+1234567890</a>   44    $87,234.0   \n",
      "25   Barbara  <a href=\"+1454545454\">+1454545454</a>   60   $666,666.0   \n",
      "26     Laura  <a href=\"+1700707700\">+1700707700</a>   12    $15,678.0   \n",
      "27       Jeb  <a href=\"+1678975123\">+1678975123</a>   34   $223,000.0   \n",
      "28  Prescott  <a href=\"+1100000000\">+1100000000</a>   52    $99,765.0   \n",
      "\n",
      "           education  Gender  consent  \n",
      "0        High School    Male        0  \n",
      "1            College    Male        1  \n",
      "2            college    Male        1  \n",
      "3    graduate school    Male        0  \n",
      "4        High School    Male        1  \n",
      "5            college    Male        1  \n",
      "6            college    Male        0  \n",
      "7    graduate school  Female        0  \n",
      "8            college  Female        1  \n",
      "9        High School  Female        0  \n",
      "10       High School  Female        1  \n",
      "11       High School  Female        1  \n",
      "12       High School  Female        1  \n",
      "13       High School    Male        1  \n",
      "14           College  Female        1  \n",
      "15           college  Female        1  \n",
      "16       High School    Male        1  \n",
      "17       High School  Female        0  \n",
      "18   graduate school    Male        1  \n",
      "19   graduate school  Female        0  \n",
      "20  graduate  school  Female        0  \n",
      "21           college    Male        0  \n",
      "22       High School    Male        1  \n",
      "23       High School    Male        1  \n",
      "24       High School    Male        1  \n",
      "25           college  Female        1  \n",
      "26       High School  Female        0  \n",
      "27       High School    Male        1  \n",
      "28       High School    Male        1  \n",
      "dataset saved in html file successfully\n"
     ]
    }
   ],
   "source": [
    "weblog_ipinfo,transactn_product,weblog,customer = loading_dataset('store_web_log.csv','ip_info.csv','store_product_table.csv','store_transaction_records.csv','customerdata.csv')\n",
    "customerweb_activity = customerweb_record(weblog_ipinfo)\n",
    "transactionrecord = transactn_record(transactn_product)\n",
    "customer_lastwebpage_visited = lastwebpage_visited_no(weblog)\n",
    "promotion_calls = promotion_record(customer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
